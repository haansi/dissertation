\chapter{Conclusion}
\label{chap:conclusion}

\epigraph{One worthwhile task carried to a successful completion is worth a hundred half-finished tasks}{\textit{B.C. Forbes}}

In the last decade, the  field of genomics has moved to a big data science, based on the development of new sequencing devices, producing GB of of data with every single run at decreasing costs. Subsequently, the bottleneck shifted from data generation to the data analysis, requiring sophisticated pipelines, in order to derive the most important informations out of the data. Further the high-throughput of the data requires reproducible and scalable methods as well as means for quality control. 

In this thesis an information-system for a small genome, the mitochondrial DNA (mtDNA) was presented, taking these preconditions into account. Mitochondrial DNA is coding the most important bioenergetic genes, with mutations involved in a variety of diseases, tumorigenesis and ageing. mtDNA Next-Generation Sequencing (NGS) facilitates detailed insights into mtDNA, enabling to identify new mutations among thousands non-mutated (heteroplasmy) in high resolution. This higher resolution requires additional caution: phantom mutations can become apparent as false positive mutations. A further major issue is the emergence of sample contamination, observable as low level heteroplasmic mutations, leading to deceptive results in medical genetic studies.
This thesis presents our previously developed tools HaploGrep in Chapter \ref{chapterHaplogrep} and mtDNA-Server in Chapter \ref{chap:NGS}, which are merged into a contamination detection system as described in Chapter \ref{chapterContamination}. The two methods are presented, to solve the two main issues:
\begin{itemize}
\item reduce false positive mutations with the help of knowledge distilled from available data sources  
\item detect sample contaminations in mtDNA NGS data
\end{itemize}
While HaploGrep automatically classifies the mtDNA profiles to haplogroups with the herein presented algorithms, a further focus is on providing means for mtDNA Quality Control for detecting issues within those profiles. The information in the phylogenetic clusters are shown to allow controls for artificial recombination, phantom mutation, false positive and false negative mutations, as presented within this work. As use case, the data set from the 1000 Genomes Project was analyzed, by demonstrating the scalability and feasibility of the presented method. For processing Fasta sequences, data from GenBank (<30,000 samples) was downloaded and performance in terms of speed and accuracy was compared to related methods.

Further, the herein described scalable web server for mtDNA NGS data analysis, directly accepts the raw reads or mapped files from NGS devices without requiring deeper bioinformatic knowledge from the end-user. Thereby the data is processed reference sequence independently and annotated according to the rCRS in highly parallel manner, by employing Apache Hadoop, running on the previously presented Cloudgene framework. As use-case, again the 1000 Genomes Phase 3 data were analyze, as well as sample mix-ups in the lab. By comparing the results with related methods, the sensitivity and specificity of the herein presented approach gets underlined.

The present work thereby describes algorithms to classify mtDNA profiles of samples into phylogenetic clusters, by comparing the results in terms of accuracy and speed. While new forms of mitochondrial therapies (like the mitochondrial replacement therapy) will become more prominent in the near future, haplogroups will become more relevant and an accurate estimation of haplogroups becomes essential. In this regard haplogroup matching is already proposed. 

To be able to compare haplogroups based on the mitochondrial profile from a DNA sequence, an alignment step is required, in order to detect the single nucleotide polymorphisms on single bases, as well as insertions or deletions of larger fragments. Different approaches to perform this task are described and an implementation of an hash-index based on k-mers and dynamic programming is presented. The approach is compared to different data structures like suffix arrays and FM-Index, the latter being widely used for Next-Generation Sequencing (NGS). 

With the previously mentioned progress in data generation by NGS, features of the mtDNA can be researched in more depth, to learn the still poorly understood process of mutation propagation. Here a new concept of processing large amount of mtDNA data derived by massive parallel sequencing devices is presented, by taking advantage of parallel computing architectures based on the MapReduce paradigm. Combined with herein described maximum likelihood model as well as filter steps, the workflow provides new insights in low-level mutations, as the result of different sequences per cell or tissue (called heteroplasmy). In order to validate the approach, several similar pipelines were compared in terms of sensitivity, specificity and precision. 

Finally the applications described within this work can all be merged into a workflow for detecting contamination in massive parallel sequencing studies. Thereby this approach is based on the concept of haplogroup detection from low-level mutations present in the sequencing data. Different approaches for contamination detection are described and the performance of the approach is evaluated based on the publicly available data-set from the 1000 Genome Consortium, providing 2,504 whole genome sequencing data (up to 4.2 Tbases per sample were generated). We could confirm sample contamination within this data-set, based on the presented approach.

In conclusion this work presents different algorithms, and implementations that can be applied for a specific task or combined to a system for performing quality control on mtDNA data. Taking advantage of the herein described computational pipeline based on the mtDNA phylogeny, false results as well as sample contamination can be detected as presented. mtDNA being present in whole genome-, whole exome sequencing or RNA-sequencing projects poses the means of an inexpensive and rapid quality control as proposed as part of this work.




